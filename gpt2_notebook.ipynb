{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Understanding AI Systems for Cybersecurity: How a Large Language Model (LLM) works?**"
      ],
      "metadata": {
        "id": "nqjJuCpbHWq-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Disclaimer: This article is made for educational purpose in the context of Cybersecurity and not replace a real training or course on Deep Learning. What's more, I've sometimes used ChatGPT or Claude to briefly explain a specific concept because I consider them to be better at it than I am.*"
      ],
      "metadata": {
        "id": "eV2yL_FjHcHv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebok follows on from the first part of an article you can read here: [Medium Article](https://medium.com/@loicmartins/understanding-ai-systems-for-cybersecurity-how-a-large-language-model-llm-works-part-1-c9bbac1728c2)\n",
        "\n",
        "The aim of these two articles is to understand the overall architecture of an LLM, rather than the complete infrastructure, in order to identify potential vulnerabilities. In the last article, I said that the key is to understand that an LLM encodes representations of the world and its output are based on these representations. If you use ChatGPT, Claude or Le Chat, you'll see that they're the same technology (almost), but that the 3 models behave differently.\n",
        "\n",
        "In the context of cybersecurity, the threat can be different, because, of course, we can find vulnerabilities in the overall infrastructure, but also within the model itself. If you're trying to exploit vulnerabilities in a web application or network, the aim may be to shut down the entire system or steal data and information. But for an LLM it can be completely different: you can modify the output of the model or “spy the input”.\n",
        "\n",
        "Modifying the output means modifying these internal representations of the model. This can be compared to manipulating a person. By talking to them, you try to change their state of mind, so that they change their behavior. And that can be very dangerous, because you can leave a model on the market that manipulates people for various purposes: politics, scams, obtaining information...\n",
        "\n",
        "That's why, in the context of cybersecurity, it's important to understand how LLM works. The level of knowledge of their inner workings you want to have will depend on your objectives (see part 1).\n",
        "\n",
        "In this article, I will show you the code behind the GPT-2 model and I will comment every steps.\n",
        "\n",
        "The code of this section is inspired by 3 main ressources:\n",
        "- Video - Andrej Karpathy - Let's build GPT: from scratch, in code, spelled out - https://www.youtube.com/watch?v=kCc8FmEb1nY - Jan 17, 2023\n",
        "- Book - Sebastian Raschka - Build a Large Language Model (From Scratch) - October 29, 2024\n",
        "- Course - Mike X Cohen - A deep understanding of deep learning - https://www.udemy.com/course/deeplearning_x/"
      ],
      "metadata": {
        "id": "wOgGy3pxIHBa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "OO0SlfacIuUE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **The spine of a GPT-2 Model**"
      ],
      "metadata": {
        "id": "RBXqJZnpKBmp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the `GPTModel` class that represents the spine of the model. When you see a number, like `(1)`, you can read the explanations below the code.\n",
        "\n",
        "Let's take a deep dive into the code, written in Python using PyTorch Library.\n",
        "\n",
        "*Disclaimer: we won’t talk about the programming or software engineering part, just the architecture of the model*."
      ],
      "metadata": {
        "id": "ktJN0DUTIxQJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ysnekh_hrayl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "\n",
        "    # (1) 2 Parts\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "\n",
        "        # (2) Embedding layer\n",
        "        self.tok_emb = nn.Embedding(config[\"vocab_size\"], config[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(config[\"context_length\"], config[\"emb_dim\"])\n",
        "\n",
        "        # (3) Dropout\n",
        "        self.drop_emb = nn.Dropout(config[\"drop_rate\"])\n",
        "\n",
        "\n",
        "        # (4) Transformer Blocks\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(config) for _ in range(config[\"n_layers\"])])\n",
        "\n",
        "        # (5) Normalization Layer\n",
        "        self.final_norm = LayerNorm(config[\"emb_dim\"])\n",
        "\n",
        "        # (6) Output layer\n",
        "        self.out_head = nn.Linear(config[\"emb_dim\"], config[\"vocab_size\"], bias=False)\n",
        "\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "\n",
        "        # (7) Embedding Layer\n",
        "        tok_embeds = self.tok_emb(in_idx) #1\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device)) #2\n",
        "        x = tok_embeds + pos_embeds #3\n",
        "\n",
        "        # (8) Regularization Layer\n",
        "        x = self.drop_emb(x)\n",
        "\n",
        "        # (9) Transformer Block\n",
        "        x = self.trf_blocks(x)\n",
        "\n",
        "        # (8) Normalization Layer\n",
        "        x = self.final_norm(x)\n",
        "\n",
        "        # (10) Output Layer\n",
        "        logits = self.out_head(x)\n",
        "\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **(1) 2 Parts**"
      ],
      "metadata": {
        "id": "y5cVFJqiI8AI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our GPT Model we have 2 parts:\n",
        "\n",
        "- `__init__`\n",
        "    * The constructor for the model class.\n",
        "    * Define the layers and components of the model.\n",
        "    * Used for initializing all the model components.\n",
        "\n",
        "- `Forward`\n",
        "    * Defines the forward pass of the model.\n",
        "    * How the input data flows through the layers that were defined in __init__."
      ],
      "metadata": {
        "id": "TizdQhzrKlLQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first part corresponds to the instantiation of a `GPTModel` object. When you run this code, `model = GPTModel()`, here's what happens:"
      ],
      "metadata": {
        "id": "k3oUcM6IKnus"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **First  Part - Constructor**"
      ],
      "metadata": {
        "id": "e8h75Qk8K3p6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **(2) Embedding layer**"
      ],
      "metadata": {
        "id": "_Ee14zRBLAza"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a reminder, this layer transforms a raw input, such as a question in human language, into an embedding matrix:\n",
        "each token has a token ID, and is represented as an n-dimensional vector.\n",
        "\n",
        "This layer initializes two matrices with random numbers (specific methods exist):\n",
        "\n",
        "*   `tok_emb`\n",
        "  *   Captures the various features for each tokens.\n",
        "  *   Rows: a token ID for each row, corresponding to the model's vocabulary.\n",
        "  *   Columns: n-dimensional columns which are numbers.\n",
        "\n",
        "*   `pos_emb`\n",
        "  *   Encodes the position of the token in the sentence.\n",
        "  *   Rows: equal to the number of the context length (=reference to the total number of tokens allowed by the model).\n",
        "  *   Columns: same dimensions as those of tok_emb."
      ],
      "metadata": {
        "id": "qujFf73hLE4j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "More information here: [Less Wrong - Article - LLM Basics: Embedding Spaces - Transformer Token Vectors Are Not Points in Space](https://www.lesswrong.com/posts/pHPmMGEMYefk9jLeh/llm-basics-embedding-spaces-transformer-token-vectors-are#1_2_The_Input_Embedding_Matrix)\n"
      ],
      "metadata": {
        "id": "jHZme3NbMSHy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **(3) Dropout**"
      ],
      "metadata": {
        "id": "p8lGq_2vMaML"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It’s a regularization method used for preventing overfitting, enhancing generalization, and stabilizing training. We initialize the method with a specific drop rate."
      ],
      "metadata": {
        "id": "0z-DJkh7Mcgf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "More information here: [DeepLearning AI - Video - Understanding Dropout (C2W1L07)](https://www.youtube.com/watch?v=ARq74QuavAo)"
      ],
      "metadata": {
        "id": "65OUQb2iMfFN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **(4) Transformer Blocks**"
      ],
      "metadata": {
        "id": "HnnFAqHbM0Dg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This layer initializes the transformer blocks. We have a For Loop, so we can instantiate several transformer blocks objects.\n",
        "\n",
        "As you know it’s the most important part of the model. This layer allows the model to:\n",
        "*   Transform input elements into enhanced context vector representations that incorporate information about all inputs.\n",
        "*   Identify and analyzes relationships between elements in the input sequence.\n",
        "\n",
        "This part of the model is very complex, and we have several other classes hidden behind the `TransformerBlock()` class. To summarize:\n",
        "\n",
        "\n",
        "*   Inside this class we have 3 main layers:\n",
        "  *   MultiHeadAttention\n",
        "  *   FeedForward\n",
        "  *   LayerNorm\n",
        "*   When the `self.trf_blocks` object is instantiated using the `TransformerBlock()` class, the model initializes different weight matrices, with random numbers (specific methods exist), inside these different layers.\n",
        "\n",
        "\n",
        "If you want to see the code of the `TransformerBlock()` class, you can look at the (9) in part 2."
      ],
      "metadata": {
        "id": "iNg8Ktr9M0Zo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "More information here:\n",
        "\n",
        "\n",
        "*   [3Blue1Brown - Video - Transformers (how LLMs work) explained visually | DL5](https://www.youtube.com/watch?v=wjZofJX0v4M)\n",
        "*   [3Blue1Brown - Video - How might LLMs store facts | DL7](https://www.youtube.com/watch?v=9-Jl0dxWQs8)\n",
        "\n"
      ],
      "metadata": {
        "id": "37SC1AVjN0F8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **(5) Normalization Layer**"
      ],
      "metadata": {
        "id": "o5jNGtclOfyB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It’s a normalization method to keep the activations stable across different layers.\n",
        "We initialize a `final_norm` object using the customize `LayerNorm()` class (code not in this article)."
      ],
      "metadata": {
        "id": "gqhy93JMOkjC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "More information here: [PyTorch - Documentation - LayerNorm](https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html)"
      ],
      "metadata": {
        "id": "nEBf8sP1QT-f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **(6) Output layer**"
      ],
      "metadata": {
        "id": "Es_t-sMkQxkv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Layer that converts the transformer output (a sequence of vectors) into logits for each token in the vocabulary. The output logits represents the next token’s unnormalized probabilities."
      ],
      "metadata": {
        "id": "NFeUfe98Q2Xd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In the context of cybersecurity, the Embedding layer and Transformation blocks seem to be the most critical, as they contain the model representations.**"
      ],
      "metadata": {
        "id": "aIXwBadEQ8Vi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "-bmt6ZDpkUi8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Second  Part - Forward Method**"
      ],
      "metadata": {
        "id": "rsxpY6mZRHTl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll now analyze the second part of the GPT model class, the `Forward` function.\n",
        "When you run the model, for training or generate text, you pass the input (token ID because we process text before) as parameter and here's what happens next:"
      ],
      "metadata": {
        "id": "TtNppY_CRU9B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **(7) Embedding Layer**"
      ],
      "metadata": {
        "id": "ODnIBFynRjWE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This first step is divided into three sub-steps:\n",
        "\n",
        "1.   We take the matrix `tok_embeds` (shape of the vocabulary), and select the rows corresponding to the token ID of the input. We obtain a new matrix of the size of the context length.\n",
        "2.   We take the `pos_emb` matrix (shape of the context length), and select a row whose index corresponds to the place of a token ID in the input sequence: select the row index 0 for the first token ID in the sequence.\n",
        "3.   We add these two matrices together, and we have a matrix with a number of rows corresponding to the context length and a number of columns corresponding to the number of dimensions we've chosen.\n"
      ],
      "metadata": {
        "id": "9jRndxewR5bV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **(8) Regularization and Normalization**"
      ],
      "metadata": {
        "id": "TJrVC-AKTMS_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These two layers are different, but they represent mathematical concepts that promote more stability and good results during training.\n",
        "\n",
        "\n",
        "\n",
        "*   **Normalization:** subtract the mean and divide by the standard deviation (square root of the variance). Then, we can scale and shift the result using two weight matrices.\n",
        "*   **Regularization Dropout:** drop a unit (along with connections) at training time with a specified probability p."
      ],
      "metadata": {
        "id": "GPz66pS2Tk_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **(9) Transformer Block**"
      ],
      "metadata": {
        "id": "Y9pO_hXCUQgR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the `GPTModel()` Class, when we call the `TransformerBlock()` class, this is what the code looks like:"
      ],
      "metadata": {
        "id": "yGcA48CQUSdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, cfg):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # (9.1) Multi-Head Attention Layer\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "\n",
        "        # (9.2) Feed Forward Layer\n",
        "        self.ff = FeedForward(cfg)\n",
        "\n",
        "        # (9.3) Regularization and Normalization\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "      # (9.5) Forward Pass\n",
        "\n",
        "        # (9.4) Shortcut connection\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "HZrouCS6Y4zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The transformer is a specific architecture and is not only used in LLMs. It's important to note that, in the case of GPT-2, we only have the decoder part of the Transformer architecture (not the encoder part).\n",
        "\n",
        "This Layer is divided in 3 main parts:\n",
        "\n",
        "1.   Multi-Head Attention Layer\n",
        "2.   Feed Forward Layer\n",
        "3.   Regularization and Normalization"
      ],
      "metadata": {
        "id": "yi4crzu-Vo4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(9.1) Multi-Head Attention Layer**\n",
        "\n",
        "This layer is a custom class represented by the code below:"
      ],
      "metadata": {
        "id": "K4QlxPiiVxf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "\n",
        "        super().__init__()\n",
        "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads\n",
        "\n",
        "        # (a)\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "\n",
        "        # (b)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # (d)\n",
        "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        # (a)\n",
        "        keys = self.W_key(x)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # (c)\n",
        "        attn_scores = queries @ keys.transpose(2, 3)\n",
        "\n",
        "        # (d)\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        # (e)\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # (f)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec)  # optional projection\n",
        "\n",
        "        return context_vec"
      ],
      "metadata": {
        "id": "OmCCmLlbd3P4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, the code is longer and more complex. I can't go into all the details in this blog post, but the attention mechanism is fundamental to LLM architecture.\n",
        "The attention mechanism allows to assess and learn the relationships and dependencies between various parts of the input itself. To be clear, it allows the model to try to understand the context and not just the word itself.\n",
        "\n",
        "To sum up, here are the main parts of the code:\n",
        "\n",
        "*   (a) = 3 weight matrices representing the foundations of the attention layer. Each matrix has a specific role, enabling the model to identify specific features.\n",
        "*   (b) = output and dropout layers as we saw previously ((6) and (3)).\n",
        "*   (c) = compute attention score, that measures how relevant a given token (or word, subwords...) in the input sequence is to another token.\n",
        "*   (d) = causal attention mask. We want the self-attention mechanism to consider only the tokens that appear prior to the current position when predicting the next token in a sequence. We don’t want later words influence earlier words, so we hide the next word(s).\n",
        "*   (e) = compute attention weights, that is a normalized version of the attention score.\n",
        "*   (f) = calculate the context vector, which is the output of the self-attention layer. This is an embedding vector enriched by the incorporation of information from all the other elements in the sequence.\n",
        "\n",
        "To illustrate the role of this layer, we can say that before the Attention layer, the model identified the different words separately, and after this layer, it can encode the relationship between the different words in the sequence."
      ],
      "metadata": {
        "id": "5wTJg1guWAA-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "More information here: [3Blue1Brown - Video - Attention in transformers, step-by-step | DL6](https://www.youtube.com/watch?v=eMlx5fFNoYc)"
      ],
      "metadata": {
        "id": "9FL_RMk-b5d5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(9.2) Feed Forward Layer**\n",
        "\n",
        "After the Multi-Head Attention Layer, we have a Feed Forward Layer. This layer can be thought of as a “basic” neural network layer (multilayer perceptron). In short, it takes the output of the multi-headed attention layer and projects it into a space n times as large, enabling exploration of a richer representation space."
      ],
      "metadata": {
        "id": "65_KlE5PcOIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "\n",
        "            # (b)\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            # (c)\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "metadata": {
        "id": "MzkLER-CjU7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have two parts:\n",
        "*   (a) = Linear layer: expand the embedding dimension to increase the number of features.\n",
        "*   (b) = Activation Function: mathematical function applied to the output of a neuron. It introduces non-linearity into the model."
      ],
      "metadata": {
        "id": "5DqWeLh4cjdp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "More information here: [NVIDIA - Article - Linear/Fully-Connected Layers User's Guide](https://docs.nvidia.com/deeplearning/performance/dl-performance-fully-connected/index.html)"
      ],
      "metadata": {
        "id": "vsE3W0ZWc4AW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(9.3) Regularization and Normalization**\n",
        "\n",
        "Same Layer that we saw previously (see (3)(5)(8))."
      ],
      "metadata": {
        "id": "mmCB3oQrd3aO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(9.4) Shortcut connection**\n",
        "\n",
        "Like regularization and normalization, shortcut connection is a performance-enhancing method. It allows information and gradients to flow more easily through the network.  \n",
        "We insert it between different layers of a neural network. This allows to skip some of the layers in the neural network and feeds the output of one layer as the input to the next layers."
      ],
      "metadata": {
        "id": "be_1qeEKd-mM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "More information here: [Analytics Vidhya - Article - What are Skip Connections in Deep Learning?](https://www.analyticsvidhya.com/blog/2021/08/all-you-need-to-know-about-skip-connections/)"
      ],
      "metadata": {
        "id": "w7GYQH3Od_vr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(9.5) Forward Pass**\n",
        "\n",
        "Like for our GPT Model class, the forward pass function:\n",
        "\n",
        "\n",
        "1.   Takes the input matrix.\n",
        "2.   Normalizes it.\n",
        "3.   Passes it through the Multi-Head Attention Layer, which output context vectors.\n",
        "4.   Applies dropout.\n",
        "5.   Adds the input of the first part of the function (shortcut connection).\n",
        "6.   Normalizes it.\n",
        "7.   Passes it through the Feed Forward Layer.\n",
        "8.   Adds the input of the second part of the function."
      ],
      "metadata": {
        "id": "w3VUfO97eOLv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*“The output of a Transformer block in an LLM is a sequence of contextualized embeddings, where each token’s representation incorporates information from other tokens in the sequence, allowing the model to capture long-range dependencies and complex relationships between words or subwords.” ChatGPT.*\n",
        "\n",
        "\n",
        "This output of the transformer block is either:\n",
        "*   used as input into a new transformer block or\n",
        "*   used as input to the ouput layer.\n"
      ],
      "metadata": {
        "id": "Bthtysd6eu7g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **(10) Output Layer**"
      ],
      "metadata": {
        "id": "jdfqO_PNfPwf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This linear layer is similar to other linear layers, but in this case, it transforms the contextualized embeddings into logits, where each logit corresponds to the likelihood of a token in the vocabulary being the next token in the sequence.\n"
      ],
      "metadata": {
        "id": "VWVN3sILfbyD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It’s the end of the code!"
      ],
      "metadata": {
        "id": "MxntufFMfg6l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What to keep in mind?"
      ],
      "metadata": {
        "id": "XnUT0g_jgUi9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The aim of this post was to give a first glimpse of what an LLM model looks like. As I said, it's a first look because:\n",
        "*   GPT-2 is “old” now, and we can find more complex and powerful models.\n",
        "*   We didn’t talk about training with backpropagation, fine tuning or hyper-parameters.\n",
        "\n",
        "The second aim of this blog is to show that LLMs hide a mysterious part: the embedding and weight matrices, which enclose the \"mind\" of LLMs. It sounds “crazy”, but LLMs represent artificial cognition. It's not human cognition, but it's still a type of cognition. So, if we look at history and the world today, we can see how dangerous it can be to manipulate human cognition. It’s why, in cybersecurity, we need people that understand AI, because malicious actors can, for example:\n",
        "*   Train their own model that talk like Hitler.\n",
        "*   Access and try to modify the inner workings of the LLM to change the outputs. You might think of a mental health app, a financial chat bot or a programming co-pilot.\n",
        "\n",
        "This is just the beginning, but a new form of hacking could emerge in the years to come. It won't just be about finding vulnerabilities in infrastructures, but perhaps also hacking into the mind of LLMs and AGI."
      ],
      "metadata": {
        "id": "PAr1bZDlgWR9"
      }
    }
  ]
}
